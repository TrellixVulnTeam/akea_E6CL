# akea
自动关键词的提取和分配系统



## 项目设计
- 基本自然语言相关处理组件越来越丰富，和对中文支持性越来越好

- doc = [text1, text2, text3... ] 全文档进来 进行新词判断 丰富词典【独立于后面分词】

- text 




## 简介
这主要是一个自然语言处理任务，本模块在结构上将尽量模仿nltk。

因为nltk主要关注于英语的处理，发现有些场景根本不适用于中文语境，然后在学习研究的过程中也接触到了一些其他模块和论文，发现有一些在中文语境下也完全不使用，但论文的思想是否有可借鉴的地方呢？

自然语言处理并不局限在分词和词性标注上，实际上我也看到其他很多杂七杂八的任务，比如简单的手机号码识别和邮箱识别，这些都应该作为辅助标注进入自然语言处理系统里面来。

包括繁简转换，同义词网络等等，所有这些手段，最终都应该融合进来，都是为了最终自然语言处理的某个目标服务的。

而现在我的主要任务就是要做一个自动关键词的提取和分配系统，这个对更上层的搜索系统和推荐系统都是很重要的一个组件功能。




## 讨论课题
- 语料库管理 corpus
- 分词 tokenize 
- 停用词去除 
- 词干化 stem 
- 繁简转换 
- 词性标注 tag
- 主题建模
- tfidf 抽取候选关键词 textrank 
- 关键词分配 受控词表 
- 同义词网络
- 文档内基于词聚类的关键词抽取
- 文档外基于LDA隐含主题模型的关键词抽取


## 分词
分词效果对于后面的步骤影响深远

- 建立更加丰富的领域词典
- 试着建立更好的新词发现机制并实时更新新词


## 停用词
关键词的抽取和分配

1. tfidf算法抽取关键词

建立新词发现 -- 发现领域新词 -- 构建vocabulary
2. 构建vocabulary来选择关键词

